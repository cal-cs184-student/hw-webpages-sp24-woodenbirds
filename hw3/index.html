<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">Yunqi Li, Franklin Zhang</h2>

<!-- Add Website URL -->
<h2 align="middle">Website URL: <a href="https://cal-cs184-student.github.io/hw-webpages-sp24-woodenbirds/hw3/index.html">https://cal-cs184-student.github.io/hw-webpages-sp24-woodenbirds/hw3/index.html</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<div>

<h2 align="middle">Overview</h2>
<p>
  In this homework, we implement a path tracer.<br>
  We first write the ray generation code to generate rays from the camera to the scene.<br>
  Then, we implement the intersection algorithm to check if the intersection with primitives in the scene.<br>
  After that, we construct a BVH to accelerate the intersection algorithm.<br>
  Then, we implement various illumination functions to calculate both direct and indirect illumination.<br>
  Also, we implement importance sampling to improve the efficiency of the direct illumination.<br>
  Finally, we implement adaptive sampling to enable the generation of noise-free images.<br>
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
  <ol>
      <li>Transform (x,y) to ((x-0.5) * tan(radians(hFov) / 2) * 2, (y-0.5) * tan(radians(vFov) / 2) * 2, -1).</li>
      <li>Transform the vector to the world coordinate by c2w.</li>
      <li>Create the ray(pos, vector).</li>
      <li>Set min_t to nClip, max_t to fClip.</li>
      <li>In function raytrace_pixel, loop ns_aa times to generate ns_aa rays from x,y.</li>
      <li>Calculate the mean of est_radiance_global_illumination(r) ns_aa rays and update the pixel x,y.</li>
  </ol>
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
  <ol>
      <li>Create function to check if a point is inside a triangle by checking if the point is on the same side of the each edge.</li>
      <li>Calculate the normal of the triangle by taking the cross product of two edges of the triangle.</li>
      <li>Calculate the intersection point by taking the dot product of the normal and a vector from the origin of the ray to a vertex of the triangle, and dividing it by the dot product of the direction of the ray and the normal.</li>
      <li>Check if the intersection point is inside range of the ray.</li>
      <li>Check if the intersection point is inside the triangle by checking if it's inside the triangle.</li>
      <li>If it is, then record the intersection point, normal((A1 / A) * n1 + (A2 / A) * n2 + (A3 / A) * n), and bsdf.</li>
      <li>Return whether there's an intersection.</li>
  </ol>
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part1_CBempty.png" align="middle" width="400px"/>
        <figcaption>CBempty.dae</figcaption>
      </td>
      <td>
        <img src="images/part1_CBspheres.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
    <ol>
		<li>Create a BBox and expand the bbox to include all primitives in the vector</li>
		<li>If the size of the vector is less than or equal to the max leaf size, return the node directly.</li>
		<li>Else, increase the current_divide_axis by 1 and mod it by 3 to get the next axis to divide. (The current_divide_axis is a static variable)</li>
		<li>Split the vector into left child and right child based on the average of the current axis.(If the current primitive's centroid equals to the average, put it in the node which has less primitives)</li>
		<li>Recursively call the construct_bvh on the left and right child.</li>
	</ol>
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/CBlucy.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
      <td>
        <img src="images/maxplanck.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/peter.png" align="middle" width="400px"/>
        <figcaption>peter.dae</figcaption>
      </td>
      <td>
        <img src="images/dragon.png" align="middle" width="400px"/>
        <figcaption>dragon.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
    Rendering cow.dae with BVH acceleration: 0.062s. Rendering cow.dae without BVH acceleration: 46.02s<br>
    Rendering beetle.date with BVH acceleration: 0.066s. Rendering beetle.date without BVH acceleration: 60.20s
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
    For the direct lighting hemisphere, we sample num_samples of points on the hemisphere and transform them to the world coordinate.<br>
    Then, we generate a ray with the hit point as the start point and the sampled point as the direction.<br>
    After that, we use bvh->intersect to check if the ray intersects with any primitives in the scene. If it does, we calculate the direct illumination and add it to L_out.<br>
    Finally, we divide L_out by num_samples to get the average direct illumination.<br><br>

    For the direct lighting importance, the num of samples for each scene light is 1 if its a point light, otherwise it's ns_area_light.<br>
    For each sample, we first use the sample_L function to get the wi, pdf of the sample and the distance from the hit_point to the light.<br>
    Then, we generate a ray with the hit point as the start point and the wi as the direction.<br>
    After that, we use bvh->intersect to check if the ray intersects with any primitives in the scene. If it doesn't, (which means the light isn't blocked), we calculate the direct illumination and add it to L_out.<br>
    Finally, we divide L_out by num_samples to get the average direct illumination.<br>
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/bunny_hemisphere.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/bunny_importance.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/sphere_hemisphere.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
      <td>
        <img src="images/sphere_importance.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/bunny_l_1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_l_4.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/bunny_l_16.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/bunny_l_64.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
    The noise level decrease as the number of light rays increase because as we have more light rays, there's more chance that the shadow ray will hit the light source and the average direct illumination will be more accurate.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
    The lighting sampling is more efficient than the uniform hemisphere sampling because it only samples the region where there's a light source. However, the uniform hemisphere sampling samples the whole hemisphere, which is inefficient. 
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
  We add a argument(num_bounces) to the at_least_one_bounce_radiance function to control the number of bounces. <br>
  If num_bounces is 0, we return L_out directly. <br>
  If num_bounces is 1, we call the one_bounce_radiance function to get the direct illumination. <br>
  If num_bounces is larger than 1, we first call the one_bounce_radiance function to get the direct illumination.<br>
  Then, we sample the bsdf to get the wi and pdf.<br>
  After that, we generate a ray with the hit point as the start point and the wi as the direction. <br>
  If the ray intersects with any primitives in the scene, we calculate the direct illumination by call the at_least_one_bounce_radiance function recursively and add it to L_out. <br>
  For Russian Roulette, we use a coin_flip function to decide whether to continue the recursion. <br>
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/global_CBbunny.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/global_CBsphere.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_direct.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/global_CBbunny_indirect.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    The roof are completely black in the direct illumination image because the light can't reach the roof directly. However, the roof are illuminated in the indirect illumination image because the light can bounce to the roof.<br>
    The back wall color is not completely grey in the indirect illumination image because the light can bounce to the multiple walls and the color of the back wall can be affected by the color of the other walls.<br>
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_m_0.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/global_CBbunny_m_1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_m_2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/global_CBbunny_m_3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_m_100.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    The max_ray_depth = 0 image is completely black except the light itself because there's no light bounce. <br>
    The max_ray_depth = 1 image is bright all the places where the light can directly reach and the light itself because there's one light bounce. <br>
    The max_ray_depth = 2 image is also bright at the roof because the light can bounce to the roof. <br>

    As the max_ray_depth increase, the image becomes brighter because the light can bounce more times and reach more places. <br>
    However, the image doesn't change much after max_ray_depth = 3 because the energy of the light is very low after 3 bounces. <br>
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_s_1.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/global_CBbunny_s_2.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_s_4.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/global_CBbunny_s_8.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_s_16.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/global_CBbunny_s_64.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/global_CBbunny_s_1024.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
    As the number of samples per pixel increase, the rendered picture becomes clearer and the noise level decrease because as we have more samples, the average illumination will be more accurate.
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
  <ol>
    <li>Loop ns_aa/samplesperBatch batches.</li>
    <li>For each batch, sample samplesperBatch times.</li>
    <li>For each sampling, update s1,s2 and total_radiance.</li>
    <li>For each batch, calculate total_n(sample times till now),mean,variance and I. If I <= maxtolerance, break the loop </li>
    <li>After the whole loop, update sampleCountBuffer with total_n.</li>
    <li>Update sampleBuffer with total_radiance/total_n.</li>
  </ol>
    </p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/part5_bunny.png" align="middle" width="400px"/>
        <figcaption>CBbunny -s 2048 -m 5</figcaption>
      </td>
      <td>
        <img src="images/part5_bunny_rate.png" align="middle" width="400px"/>
        <figcaption>CBbunny_rate -s 2048 -m 5</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/part5_CBspheres_lambertian.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian -s 2048 -m 5</figcaption>
      </td>
      <td>
        <img src="images/part5_CBspheres_lambertian_rate.png" align="middle" width="400px"/>
        <figcaption>CBspheres_lambertian_rate -s 2048 -m 5</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
